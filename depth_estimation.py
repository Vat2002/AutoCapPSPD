import cv2import numpy as npimport torchimport matplotlib.pyplot as pltimport sslfrom PIL import Imagefrom ultralytics import YOLOfrom collections import Counterssl._create_default_https_context = ssl._create_unverified_contextdef depth_est(filename):    image = Image.open(filename)    yolo_model = YOLO('model/yolov8n.pt')    results = yolo_model.predict(image)    # Extract relevant information from YOLO results    classes = results[0].boxes.cls.tolist()    names = results[0].names    # Check for at least two identical objects    class_counts = Counter(names[int(cls)] for cls in classes)    common_objects = [name for name, count in class_counts.items() if count >= 2]    model_type = "MiDaS_small"  # MiDaS v3 - Large     (highest accuracy, slowest inference speed)    midas = torch.hub.load("intel-isl/MiDaS", model_type)    device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")    midas.to(device)    midas.eval()    midas_transforms = torch.hub.load("intel-isl/MiDaS", "transforms")    if model_type == "DPT_Large" or model_type == "DPT_Hybrid":        transform = midas_transforms.dpt_transform    else:        transform = midas_transforms.small_transform    if common_objects:  # At least two of the same object detected        print("REPEATING OBJECTS PERFORMING DEPTH:")        img = cv2.imread(filename)        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        input_batch = transform(img_rgb).to(device)        with torch.no_grad():            prediction = midas(input_batch)            prediction = torch.nn.functional.interpolate(                prediction.unsqueeze(1),                size=img.shape[:2],                mode="bicubic",                align_corners=False,            ).squeeze()        output = prediction.cpu().numpy()        result = results[0]        # Draw bounding boxes and depth information        for box in result.boxes:            x1, y1, x2, y2 = [round(x) for x in box.xyxy[0].tolist()]            class_id = box.cls[0].item()            prob = round(box.conf[0].item(), 2)            depth_value = np.mean(output[y1:y2, x1:x2])  # Get average depth value for the area of the box            # Draw rectangle on the image            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)            cv2.putText(img, f"{result.names[class_id]}: {prob}, Depth: {depth_value:.2f}", (x1, y1 - 10),                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)            print(f"{result.names[class_id]}: {prob}, Depth: {depth_value:.2f}")        # Display the image        plt.imshow(output, cmap='inferno')        plt.show()        cv2.imshow("Detected Objects with Depth", img)        cv2.waitKey(0)        cv2.destroyAllWindows()    else:        print("NO REPEATING OBJECTS!")depth_est("test_images/muldog.jpeg")